{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-01T07:13:01.166145Z",
     "start_time": "2023-08-01T07:12:58.178541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "\n",
    "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=True)\n",
    "\n",
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-shirt/top  T-shirt/top  Sneaker  Dress\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print('  '.join(classes[labels[j]] for j in range(4)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T07:15:46.422628Z",
     "start_time": "2023-08-01T07:15:45.571834Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyTorch models inherit from torch.nn.Module\n",
    "class GarmentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GarmentClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = GarmentClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T07:22:13.900358Z",
     "start_time": "2023-08-01T07:22:13.890187Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4742, 0.1369, 0.4131, 0.9271, 0.4687, 0.6643, 0.1599, 0.4878, 0.7488,\n",
      "         0.2144],\n",
      "        [0.3068, 0.1854, 0.3482, 0.7940, 0.2544, 0.0216, 0.6957, 0.9444, 0.7480,\n",
      "         0.3259],\n",
      "        [0.0580, 0.6257, 0.5119, 0.0250, 0.8717, 0.2832, 0.2128, 0.5402, 0.4797,\n",
      "         0.3014],\n",
      "        [0.3334, 0.4202, 0.6493, 0.6879, 0.3004, 0.6691, 0.5972, 0.0921, 0.2706,\n",
      "         0.2597]])\n",
      "tensor([1, 5, 3, 7])\n",
      "Total loss for this batch: 2.702655792236328\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# NB: Loss functions expect data in batches, so we're creating batches of 4\n",
    "# Represents the model's confidence in each of the 10 classes for a given input\n",
    "dummy_outputs = torch.rand(4, 10)\n",
    "# Represents the correct class among the 10 being tested\n",
    "dummy_labels = torch.tensor([1, 5, 3, 7])\n",
    "\n",
    "print(dummy_outputs)\n",
    "print(dummy_labels)\n",
    "\n",
    "loss = loss_fn(dummy_outputs, dummy_labels)\n",
    "print('Total loss for this batch: {}'.format(loss.item()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T07:22:36.964388Z",
     "start_time": "2023-08-01T07:22:36.947764Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_labels.size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T07:37:15.689557Z",
     "start_time": "2023-08-01T07:37:15.672715Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T07:56:42.050582Z",
     "start_time": "2023-08-01T07:56:42.044742Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T07:56:44.887560Z",
     "start_time": "2023-08-01T07:56:44.884026Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 1000 loss: 1.8731963924765587\n",
      "  batch 2000 loss: 0.8793741011433304\n",
      "  batch 3000 loss: 0.7451804595831781\n",
      "  batch 4000 loss: 0.6843764821682126\n",
      "  batch 5000 loss: 0.6158571792137809\n",
      "  batch 6000 loss: 0.5904830325900111\n",
      "  batch 7000 loss: 0.5522414886669721\n",
      "  batch 8000 loss: 0.5374252503786702\n",
      "  batch 9000 loss: 0.526074154210859\n",
      "  batch 10000 loss: 0.4921687937560491\n",
      "  batch 11000 loss: 0.46801200476533267\n",
      "  batch 12000 loss: 0.4584750946051208\n",
      "  batch 13000 loss: 0.4372786838645116\n",
      "  batch 14000 loss: 0.4309826119132922\n",
      "  batch 15000 loss: 0.4041162303240271\n",
      "LOSS train 0.4041162303240271 valid 0.4261987805366516\n",
      "EPOCH 2:\n",
      "  batch 1000 loss: 0.38655337145505475\n",
      "  batch 2000 loss: 0.40989012912729234\n",
      "  batch 3000 loss: 0.3912595315951912\n",
      "  batch 4000 loss: 0.3887749727809569\n",
      "  batch 5000 loss: 0.40446680839476173\n",
      "  batch 6000 loss: 0.39400565720432495\n",
      "  batch 7000 loss: 0.3812233217082685\n",
      "  batch 8000 loss: 0.36510691079485696\n",
      "  batch 9000 loss: 0.38641429059772053\n",
      "  batch 10000 loss: 0.3764335421041469\n",
      "  batch 11000 loss: 0.3764016893412336\n",
      "  batch 12000 loss: 0.3829249073722167\n",
      "  batch 13000 loss: 0.34474376208829927\n",
      "  batch 14000 loss: 0.34290551422163845\n",
      "  batch 15000 loss: 0.3554888208225166\n",
      "LOSS train 0.3554888208225166 valid 0.3701637089252472\n",
      "EPOCH 3:\n",
      "  batch 1000 loss: 0.36240090577013323\n",
      "  batch 2000 loss: 0.32765287689716205\n",
      "  batch 3000 loss: 0.3374013190258411\n",
      "  batch 4000 loss: 0.32316771734094074\n",
      "  batch 5000 loss: 0.3256984728761163\n",
      "  batch 6000 loss: 0.3286433316886541\n",
      "  batch 7000 loss: 0.3358452120489674\n",
      "  batch 8000 loss: 0.30711711742581976\n",
      "  batch 9000 loss: 0.337847679366947\n",
      "  batch 10000 loss: 0.3400035525802232\n",
      "  batch 11000 loss: 0.326836488408866\n",
      "  batch 12000 loss: 0.3399696338063659\n",
      "  batch 13000 loss: 0.32376691688233405\n",
      "  batch 14000 loss: 0.3468957879869267\n",
      "  batch 15000 loss: 0.3070911312564276\n",
      "LOSS train 0.3070911312564276 valid 0.33004701137542725\n",
      "EPOCH 4:\n",
      "  batch 1000 loss: 0.30301203172958047\n",
      "  batch 2000 loss: 0.3001460323657884\n",
      "  batch 3000 loss: 0.30370640737965005\n",
      "  batch 4000 loss: 0.3162484225621156\n",
      "  batch 5000 loss: 0.31321828890329195\n",
      "  batch 6000 loss: 0.29574474748835566\n",
      "  batch 7000 loss: 0.30429268602139925\n",
      "  batch 8000 loss: 0.3214976699271356\n",
      "  batch 9000 loss: 0.29027836518040934\n",
      "  batch 10000 loss: 0.30546323553981347\n",
      "  batch 11000 loss: 0.3143375391889276\n",
      "  batch 12000 loss: 0.29374250165963167\n",
      "  batch 13000 loss: 0.3207077450143888\n",
      "  batch 14000 loss: 0.29920033607154617\n",
      "  batch 15000 loss: 0.27970753210071414\n",
      "LOSS train 0.27970753210071414 valid 0.3216651976108551\n",
      "EPOCH 5:\n",
      "  batch 1000 loss: 0.266611966239816\n",
      "  batch 2000 loss: 0.2742580146914879\n",
      "  batch 3000 loss: 0.272597378780978\n",
      "  batch 4000 loss: 0.28530536381562704\n",
      "  batch 5000 loss: 0.27484028003448113\n",
      "  batch 6000 loss: 0.2861918505212088\n",
      "  batch 7000 loss: 0.3079141149421776\n",
      "  batch 8000 loss: 0.31721137561203794\n",
      "  batch 9000 loss: 0.2882230232366637\n",
      "  batch 10000 loss: 0.2857425767425157\n",
      "  batch 11000 loss: 0.2762545836429126\n",
      "  batch 12000 loss: 0.30243181294560784\n",
      "  batch 13000 loss: 0.3046174954074304\n",
      "  batch 14000 loss: 0.26063948952493954\n",
      "  batch 15000 loss: 0.28722659371698867\n",
      "LOSS train 0.28722659371698867 valid 0.31586283445358276\n"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T08:18:43.684676Z",
     "start_time": "2023-08-01T08:14:12.894576Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
